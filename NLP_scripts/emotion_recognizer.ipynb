{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "first-austria",
   "metadata": {},
   "source": [
    "# Emotion Recognition from text\n",
    "\n",
    "This code takes some data that I found on the internet with some text labeled with 5 emotions and then trains a neural network model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try and do some deep learning models in pycharm\n",
    "# Importing the final data that we want to analyse\n",
    "\n",
    "# give credit to https://github.com/rmohashi/emotion-from-tweet/blob/master/notebooks/Train%20Emotion%20Recognition%20Model.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# download training and test data\n",
    "train_df = pd.DataFrame(columns=['text', 'labels'])\n",
    "test_df = pd.DataFrame(columns=['text', 'labels' ])\n",
    "with open('data/train.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        train_df = train_df.append({'text': line.split(';')[0],\n",
    "                                    'labels': line.split(';')[1][:-1]\n",
    "                                    }, ignore_index=True)\n",
    "with open('data/test.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        test_df = test_df.append({'text': line.split(';')[0],\n",
    "                                 'labels': line.split(';')[1][:-1]\n",
    "                                  }, ignore_index=True)\n",
    "\n",
    "train_data = pd.read_csv('data/training_set.csv')\n",
    "test_data = pd.read_csv('data/test_set.csv')\n",
    "\n",
    "# We actually have 2 different sets but i am going to use the second one first because it has more lines\n",
    "# we will see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "asian-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we need to turn the text into numbers...\n",
    "# The basic idea of word embedding is words that occur in similar context tend to be closer to each\n",
    "# other in vector space. For generating word vectors in Python, modules needed are nltk and gensim.\n",
    "\n",
    "# importing all necessary modules\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from pathlib import Path\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "painful-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "#all_sentences = nltk.sent_tokenize(all_data_string)\n",
    "#all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "\n",
    "def clean_data(data):\n",
    "    # This function takes an array of strings and returns an array of cleaned up strings\n",
    "    cleaned_data = []\n",
    "    for row,texts in enumerate(data):\n",
    "        texts = str(texts)\n",
    "        texts = texts.lower()\n",
    "        # remove special characters\n",
    "        texts = texts.replace(r\"(http|@)\\S+\", \"\")\n",
    "        texts = texts.replace(r\"::\", \" \")\n",
    "        texts = texts.replace(r\"â€™\", \"\")\n",
    "        texts = texts.replace(r\",\", \" \")\n",
    "        texts = texts.replace(r\"[^a-z\\':_]\", \" \")\n",
    "        # remove repetition\n",
    "        #pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
    "        #texts = texts.replace(pattern, r\"\\1\")\n",
    "        # Transform short negation form\n",
    "        texts = texts.replace(r\"(can't|cannot)\", 'can not')\n",
    "        texts = texts.replace(r\"n't\", ' not')\n",
    "        # Remove stop words\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        stopwords.remove('not')\n",
    "        stopwords.remove('nor')\n",
    "        stopwords.remove('no')\n",
    "        cleaned_line = ''\n",
    "        for word in texts.split(\" \"):\n",
    "            if word not in stopwords:\n",
    "                cleaned_line = cleaned_line + \" \" + word\n",
    "        cleaned_data.append(cleaned_line)\n",
    "    return cleaned_data\n",
    "\n",
    "\n",
    "train_data['Text'] = clean_data(train_data['Text'])\n",
    "test_data['Text'] = clean_data(test_data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technical-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the data is cleaned up we need to tokenize it\n",
    "num_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=True)\n",
    "tokenizer.fit_on_texts(train_data.Text)\n",
    "\n",
    "file_to_save = Path('../Mygov_feedback_outputs/models/tokenizer.pickle').resolve()\n",
    "with file_to_save.open('wb') as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "auburn-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is tokenized - now lets try putting it in the model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# define model params\n",
    "input_dim = min(tokenizer.num_words, len(tokenizer.word_index) + 1)\n",
    "num_classes = len(train_data.Emotion.unique())\n",
    "embedding_dim = 500\n",
    "input_length = 100\n",
    "lstm_units = 128\n",
    "lstm_dropout = 0.1\n",
    "recurrent_dropout = 0.1\n",
    "spatial_dropout=0.2\n",
    "filters=64\n",
    "kernel_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stupid-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 500)     5000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 100, 500)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 100, 256)     644096      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 98, 64)       49216       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 64)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            645         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 5,693,957\n",
      "Trainable params: 5,693,957\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "input_layer = Input(shape=(input_length,))\n",
    "output_layer = Embedding(\n",
    "  input_dim=input_dim,\n",
    "  output_dim=embedding_dim,\n",
    "  input_shape=(input_length,)\n",
    ")(input_layer)\n",
    "\n",
    "output_layer = SpatialDropout1D(spatial_dropout)(output_layer)\n",
    "\n",
    "output_layer = Bidirectional(\n",
    "LSTM(lstm_units, return_sequences=True,\n",
    "     dropout=lstm_dropout, recurrent_dropout=recurrent_dropout)\n",
    ")(output_layer)\n",
    "output_layer = Conv1D(filters, kernel_size=kernel_size, padding='valid',\n",
    "                    kernel_initializer='glorot_uniform')(output_layer)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(output_layer)\n",
    "max_pool = GlobalMaxPooling1D()(output_layer)\n",
    "output_layer = concatenate([avg_pool, max_pool])\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax')(output_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acknowledged-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets prep the model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# turn into arrays of words not strings\n",
    "train_sequences = [text.split() for text in train_data.Text]\n",
    "validation_sequences = [text.split() for text in test_data.Text]\n",
    "# turn into array of integers\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(train_sequences)\n",
    "list_tokenized_validation = tokenizer.texts_to_sequences(validation_sequences)\n",
    "# pad out the arrays\n",
    "x_train = pad_sequences(list_tokenized_train, maxlen=input_length)\n",
    "x_validation = pad_sequences(list_tokenized_validation, maxlen=input_length)\n",
    "# encode the data\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_data.Emotion.unique())\n",
    "\n",
    "encoder_path = Path('../Mygov_feedback_outputs/models', 'encoder.pickle')\n",
    "with encoder_path.open('wb') as file:\n",
    "    pickle.dump(encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "excited-treasurer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "62/62 [==============================] - 32s 508ms/step - loss: 0.3086 - accuracy: 0.9036 - val_loss: 1.1057 - val_accuracy: 0.6785\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - 33s 535ms/step - loss: 0.2269 - accuracy: 0.9299 - val_loss: 1.2502 - val_accuracy: 0.6684\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - 32s 519ms/step - loss: 0.1837 - accuracy: 0.9427 - val_loss: 1.4093 - val_accuracy: 0.6658\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - 32s 520ms/step - loss: 0.1497 - accuracy: 0.9555 - val_loss: 1.5956 - val_accuracy: 0.6581\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - 32s 520ms/step - loss: 0.1331 - accuracy: 0.9609 - val_loss: 1.7031 - val_accuracy: 0.6611\n"
     ]
    }
   ],
   "source": [
    "y_train = encoder.transform(train_data.Emotion)\n",
    "y_validation = encoder.transform(test_data.Emotion)\n",
    "\n",
    "# Ready to train the model now\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "distinct-transport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.ylim(ymin=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "answering-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = pd.read_excel('data/raw_data.xlsx')\n",
    "\n",
    "columns_with_open_ended_data = ['Q02', 'Q04', 'Q06', 'Q08', 'Q10', 'Q12', 'Q14']\n",
    "data = survey_data[columns_with_open_ended_data]\n",
    "data = data.reset_index()\n",
    "data = data[1:]\n",
    "data = data.drop(columns = ['index'])\n",
    "all_values = []\n",
    "for column in data:\n",
    "    this_column_values = data[column].tolist()\n",
    "    all_values += this_column_values\n",
    "one_column_df = pd.DataFrame(all_values)\n",
    "one_column_df = one_column_df.dropna()\n",
    "data = one_column_df.reset_index()\n",
    "data = data.drop(columns = ['index'])\n",
    "data = np.array(data)\n",
    "data = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-official",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "plastic-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the data into a vector using the tokenizer from the model\n",
    "def emotion_predictor(data):\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    list_tokenized_data = tokenizer.texts_to_sequences(current_data)\n",
    "    x_padded = pad_sequences(list_tokenized_data, maxlen=input_length)\n",
    "\n",
    "    predicted = model.predict(x_padded)\n",
    "    emotions_dictionary = { '1' : 'anger',\n",
    "                            '2' : 'fear',\n",
    "                            '3' : 'joy',\n",
    "                            '4' : 'neutral',\n",
    "                            '5' : 'sadness'}\n",
    "\n",
    "    averages = predicted.mean(axis=0)\n",
    "    emotions_df = pd.DataFrame(columns=['Emotion','Average'])\n",
    "    \n",
    "    for i,number in enumerate(averages):\n",
    "        emotions_df = emotions_df.append({ 'Emotion' : emotions_dictionary[str(i+1)],\n",
    "                                       'Average' : number},\n",
    "                                     ignore_index=True)\n",
    "    #print(emotions_dictionary[str(i+1)],\" = \",number)\n",
    "    emotions_df = emotions_df.set_index('Emotion')\n",
    "\n",
    "    return emotions_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "earned-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_data = survey_data[columns_with_open_ended_data][1:]\n",
    "emotions_questions = pd.DataFrame(columns=['Question', 'anger', 'fear', 'joy', 'neutral', 'sadness'])\n",
    "\n",
    "for current_column in columns_data:\n",
    "    current_data = columns_data['Q02']\n",
    "    current_data = current_data.dropna()\n",
    "    current_data.reset_index()\n",
    "    current_data = current_data.drop(columns=['index'])\n",
    "    current_data = current_data.to_list()\n",
    "    current_data = np.array(current_data)\n",
    "    #print(current_data)\n",
    "    current_emotions = emotion_predictor(current_data)\n",
    "    emotions_questions = emotions_questions.append({'Question' : current_column,\n",
    "                                                   'anger': current_emotions.loc['anger'][0],\n",
    "                                                   'fear': current_emotions.loc['fear'][0],\n",
    "                                                   'joy': current_emotions.loc['joy'][0],\n",
    "                                                   'neutral': current_emotions.loc['neutral'][0],\n",
    "                                                   'sadness': current_emotions.loc['sadness'][0]\n",
    "                                                   }, ignore_index= True)\n",
    "emotions_questions = emotions_questions.append({'Question': 'Average',\n",
    "                                                'anger': emotions_questions.mean()['anger'],\n",
    "                                               'fear': emotions_questions.mean()['fear'],\n",
    "                                               'joy': emotions_questions.mean()['joy'],\n",
    "                                               'neutral': emotions_questions.mean()['neutral'],\n",
    "                                               'sadness': emotions_questions.mean()['sadness']\n",
    "                                               },ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "acknowledged-stage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q02</td>\n",
       "      <td>0.169689</td>\n",
       "      <td>0.255936</td>\n",
       "      <td>0.200030</td>\n",
       "      <td>0.052549</td>\n",
       "      <td>0.321795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q04</td>\n",
       "      <td>0.154503</td>\n",
       "      <td>0.263786</td>\n",
       "      <td>0.167543</td>\n",
       "      <td>0.055680</td>\n",
       "      <td>0.358488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q06</td>\n",
       "      <td>0.167076</td>\n",
       "      <td>0.257071</td>\n",
       "      <td>0.169077</td>\n",
       "      <td>0.047387</td>\n",
       "      <td>0.359389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q08</td>\n",
       "      <td>0.154666</td>\n",
       "      <td>0.254881</td>\n",
       "      <td>0.163440</td>\n",
       "      <td>0.052702</td>\n",
       "      <td>0.374311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q10</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>0.252206</td>\n",
       "      <td>0.153849</td>\n",
       "      <td>0.061308</td>\n",
       "      <td>0.371837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q12</td>\n",
       "      <td>0.160216</td>\n",
       "      <td>0.250237</td>\n",
       "      <td>0.151817</td>\n",
       "      <td>0.063602</td>\n",
       "      <td>0.374128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q14</td>\n",
       "      <td>0.183793</td>\n",
       "      <td>0.238476</td>\n",
       "      <td>0.136337</td>\n",
       "      <td>0.063375</td>\n",
       "      <td>0.378018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.164392</td>\n",
       "      <td>0.253227</td>\n",
       "      <td>0.163156</td>\n",
       "      <td>0.056658</td>\n",
       "      <td>0.362567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question     anger      fear       joy   neutral   sadness\n",
       "0      Q02  0.169689  0.255936  0.200030  0.052549  0.321795\n",
       "1      Q04  0.154503  0.263786  0.167543  0.055680  0.358488\n",
       "2      Q06  0.167076  0.257071  0.169077  0.047387  0.359389\n",
       "3      Q08  0.154666  0.254881  0.163440  0.052702  0.374311\n",
       "4      Q10  0.160799  0.252206  0.153849  0.061308  0.371837\n",
       "5      Q12  0.160216  0.250237  0.151817  0.063602  0.374128\n",
       "6      Q14  0.183793  0.238476  0.136337  0.063375  0.378018\n",
       "7  Average  0.164392  0.253227  0.163156  0.056658  0.362567"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "amended-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_questions.to_csv('data/output/recognized_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-discretion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-advertising",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
